import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'package:flutter/services.dart';
import 'package:flutter/foundation.dart';
import 'package:path_provider/path_provider.dart';
import 'package:vosk_flutter/vosk_flutter.dart';

class VoskRecognitionService {
  VoskFlutterPlugin? _vosk;
  Model? _model;
  Recognizer? _recognizer;

  bool _isInitialized = false;
  bool _isListening = false;

  Timer? _audioTimer;

  final List<String> stopCommands = [
    '—Å—Ç–æ–ø',
    'stop',
    '–æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å',
    '–æ—Å—Ç–∞–Ω–æ–≤–∏—Å—å',
    '—Ö–≤–∞—Ç–∏—Ç',
    '–∑–∞–∫–æ–Ω—á–∏—Ç—å',
    '—Å—Ç–æ–ø–∞–π',
    '–æ—Å—Ç–∞–Ω–æ–≤–∫–∞',
  ];

  final Function() onStopCommand;

  VoskRecognitionService({required this.onStopCommand});

  Future<void> initialize() async {
    if (_isInitialized) return;

    try {
      _vosk = VoskFlutterPlugin.instance();

      // –ö–æ–ø–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –∏–∑ assets –≤ –¥–æ–∫—É–º–µ–Ω—Ç—ã
      final modelPath = await _extractModelFromAssets();

      // –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
      _model = await _vosk!.createModel(modelPath);

      // –°–æ–∑–¥–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å (16000 Hz - —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è vosk)
      _recognizer = await _vosk!.createRecognizer(
        model: _model!,
        sampleRate: 16000,
      );

      // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–ª—É—à–∞—Ç–µ–ª—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
      if (_recognizer != null) {
        _recognizer!.setResultListener((result) {
          debugPrint('üé§ Vosk result: $result');
          _checkForStopCommand(result);
        });

        _recognizer!.setPartialResultListener((partial) {
          debugPrint('üé§ Vosk partial: $partial');
          _checkForStopCommand(partial);
        });
      }

      _isInitialized = true;
      debugPrint('‚úÖ Vosk initialized successfully');
    } catch (e) {
      debugPrint('‚ùå Error initializing Vosk: $e');
      rethrow;
    }
  }

  Future<String> _extractModelFromAssets() async {
    final directory = await getApplicationDocumentsDirectory();
    final modelPath = '${directory.path}/vosk-model-small-ru';

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å
    final modelDir = Directory(modelPath);
    if (await modelDir.exists()) {
      debugPrint('Model already exists at $modelPath');
      return modelPath;
    }

    // –ö–æ–ø–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –∏–∑ assets
    debugPrint('Extracting model to $modelPath...');
    await modelDir.create(recursive: true);

    // –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –∏–∑ assets
    final manifestContent = await rootBundle.loadString('AssetManifest.json');
    final Map<String, dynamic> manifestMap = json.decode(manifestContent);

    // –ö–æ–ø–∏—Ä—É–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–∏
    final modelFiles = manifestMap.keys
        .where(
          (String key) => key.startsWith('assets/models/vosk-model-small-ru/'),
        )
        .toList();

    for (final assetPath in modelFiles) {
      final relativePath = assetPath.replaceFirst(
        'assets/models/vosk-model-small-ru/',
        '',
      );
      if (relativePath.isEmpty) continue;

      final targetPath = '$modelPath/$relativePath';
      final targetFile = File(targetPath);

      // –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
      await targetFile.parent.create(recursive: true);

      // –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª
      final data = await rootBundle.load(assetPath);
      await targetFile.writeAsBytes(data.buffer.asUint8List());

      debugPrint('Copied: $relativePath');
    }

    debugPrint('‚úÖ Model extracted successfully');
    return modelPath;
  }

  Future<void> startListening() async {
    if (!_isInitialized) {
      await initialize();
    }

    if (_isListening) return;

    try {
      // –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω —á–µ—Ä–µ–∑ recognizer
      _recognizer?.start();
      _isListening = true;

      // –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è–µ–º –∞—É–¥–∏–æ (–≤ –≤–µ—Ä—Å–∏–∏ 0.3.48 –Ω—É–∂–Ω–æ –≤—Ä—É—á–Ω—É—é —á–∏—Ç–∞—Ç—å)
      _startAudioProcessing();

      debugPrint('‚úÖ Vosk: Started continuous listening');
    } catch (e) {
      debugPrint('‚ùå Error starting Vosk listening: $e');
      rethrow;
    }
  }

  void _startAudioProcessing() {
    // –í –≤–µ—Ä—Å–∏–∏ 0.3.48 –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∞–π–º–µ—Ä –¥–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è
    _audioTimer = Timer.periodic(const Duration(milliseconds: 100), (
      timer,
    ) async {
      if (!_isListening) {
        timer.cancel();
        return;
      }

      try {
        // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
        await _recognizer?.acceptWaveform();
      } catch (e) {
        debugPrint('Error processing audio: $e');
      }
    });
  }

  void _checkForStopCommand(String text) {
    // –ü–∞—Ä—Å–∏–º JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    try {
      final result = json.decode(text);
      final recognizedText = (result['text'] ?? result['partial'] ?? '')
          .toString()
          .toLowerCase();

      for (final command in stopCommands) {
        if (recognizedText.contains(command)) {
          debugPrint('üõë Stop command detected: $command');
          onStopCommand();
          break;
        }
      }
    } catch (e) {
      // –ï—Å–ª–∏ –Ω–µ JSON, –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ø—Ä—è–º—É—é
      final lowerText = text.toLowerCase();
      for (final command in stopCommands) {
        if (lowerText.contains(command)) {
          debugPrint('üõë Stop command detected: $command');
          onStopCommand();
          break;
        }
      }
    }
  }

  Future<void> stopListening() async {
    if (!_isListening) return;

    try {
      _audioTimer?.cancel();
      _audioTimer = null;

      _recognizer?.stop();

      _isListening = false;

      debugPrint('‚úÖ Vosk: Stopped listening');
    } catch (e) {
      debugPrint('‚ùå Error stopping Vosk: $e');
    }
  }

  Future<void> dispose() async {
    await stopListening();

    _recognizer?.dispose();
    _model?.dispose();

    _recognizer = null;
    _model = null;
    _isInitialized = false;
  }
}
